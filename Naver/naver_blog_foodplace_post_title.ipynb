{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import os.path\n",
    "import ast\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import openpyxl\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.common.exceptions import SessionNotCreatedException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import NoSuchWindowException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 동적 웹 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 맛집 블로그 포스트 100개 크롤링 - 제목, url, 장소명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPostDate(post_title):        \n",
    "    # 검색된 포스트의 날짜 구하기 - Naver API 활용\n",
    "    client_id = \"XVCwmN8OWSwXTVWc2_uQ\"\n",
    "    client_secret = \"45zos8jb_F\"\n",
    "\n",
    "    encText = urllib.parse.quote(str(post_title))\n",
    "\n",
    "    url = \"https://openapi.naver.com/v1/search/blog?query=\" + encText # JSON 결과\n",
    "    display_num = \"1\" #출력할 갯수 입력받기\n",
    "    url = \"https://openapi.naver.com/v1/search/blog?query=\" + encText +\"&display=\"+display_num# json 결과\n",
    "    # url = \"https://openapi.naver.com/v1/search/blog.xml?query=\" + encText # XML 결과\n",
    "    request = urllib.request.Request(url)\n",
    "    request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "    request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "    response = urllib.request.urlopen(request)\n",
    "    rescode = response.getcode()\n",
    "    if(rescode==200):\n",
    "        response_body = response.read().decode('utf-8')\n",
    "        # print(response_body)\n",
    "        # json 파일로 변경\n",
    "        with open(\"response.json\", \"w\") as json_file:\n",
    "            json.dump(response_body, json_file)\n",
    "        res_json = json.dumps(response_body, indent=4, sort_keys=True)\n",
    "        with open(\"response.json\", \"r\") as response_json:\n",
    "            res_python = json.load(response_json)\n",
    "\n",
    "        #items key 값만 뽑기\n",
    "        my_dict = ast.literal_eval(res_python)\n",
    "        list_str = str(my_dict[\"items\"])[1:-1]\n",
    "        # json 파일로 변경\n",
    "        with open(\"items.json\", \"w\") as json_file:\n",
    "            json.dump(list_str, json_file)\n",
    "        res_json = json.dumps(list_str, indent=4, sort_keys=True)\n",
    "        with open(\"items.json\", \"r\") as response_json:\n",
    "            res_python = json.load(response_json)\n",
    "        my_dict = ast.literal_eval(res_python)\n",
    "        postdate = my_dict[\"postdate\"]\n",
    "        # print(\"postdate : {}\".format(postdate))\n",
    "    else:\n",
    "        print(\"Error Code:\" + rescode)\n",
    "    return postdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetResInfo(raw_url):\n",
    "\n",
    "    temp = []\n",
    "    tags = []\n",
    "\n",
    "    #파싱 가능한 실제 viewer url 얻기\n",
    "    # print(raw_url)\n",
    "    url = \"view-source:{}\".format(raw_url)\n",
    "    # print(url)\n",
    "\n",
    "    try:\n",
    "        driver = webdriver.Chrome()\n",
    "        #크롬 드라이버 설치 링크 : https:storage.googleapis.com/chrome-for-testing-public/127.0.6533.72/win64/chromedriver-win64.zip\n",
    "        #압축 해제 후, driver.exe는 실행파일과 같은 위치 혹은 하위에 존재해야 함\n",
    "        #사내망에선 드라이버의 물리적 위치 괄호 안에 지정해줘야 함\n",
    "    except SessionNotCreatedException as e:\n",
    "        print(\"SessionNotCreatedExceptions이 발생했습니다:\", str(e))\n",
    "\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    a = driver.find_element(By.CSS_SELECTOR, 'body > table > tbody > tr:nth-child(76) > td.line-content > a').text\n",
    "    # print(a)\n",
    "    real_url = \"https://blog.naver.com{}\".format(a)\n",
    "    \n",
    "    #파싱 가능한 url로 재진입\n",
    "    driver.get(real_url)\n",
    "    time.sleep(3)\n",
    "    print(real_url)\n",
    "\n",
    "    #식당명, 식당주소 얻기\n",
    "    page = urllib.request.urlopen(real_url)\n",
    "    soup = BeautifulSoup(page,'html.parser')\n",
    "    try:\n",
    "        # for tag in soup.find_all(class_='se-map-title'):\n",
    "        for tag in soup.find(class_='se-map-title'):\n",
    "            restaurant_name = tag.get_text()\n",
    "            print(restaurant_name)\n",
    "        # for tag in soup.find_all(class_='se-map-address'):\n",
    "        for tag in soup.find(class_='se-map-address'):\n",
    "            restaurant_adress = tag.get_text()\n",
    "            print(restaurant_adress)\n",
    "    except TypeError as e:\n",
    "        restaurant_name = \"\"\n",
    "        restaurant_adress = \"\"\n",
    "        print(\"본문내 지도 위젯이 없습니다.\")\n",
    "\n",
    "    # 해시태그 확인용 url 재진입\n",
    "    # 해시태그 얻기    \n",
    "    # b = driver.find_element(By.CSS_SELECTOR, '#post_footer_contents').text\n",
    "    # str(b).split('\\n')\n",
    "    # temp = list(b.split('\\n'))\n",
    "    # tags = temp[4:-1]\n",
    "    # print(tags)\n",
    "\n",
    "    #해시태그 얻기_2024.08.26 수정\n",
    "    b = driver.find_element(By.CSS_SELECTOR, '#post_footer_contents').text\n",
    "    temp = list(str(b).split('\\n'))\n",
    "    tags = temp[1:]\n",
    "    if '영리적 사용 불가' in tags:\n",
    "        tags.remove('영리적 사용 불가')\n",
    "    if '내용 변경 불가' in tags:\n",
    "        tags.remove('내용 변경 불가')\n",
    "    if '태그' in tags:\n",
    "        tags.remove('태그')\n",
    "    tags_ = ', '.join(tags)\n",
    "    # print(tags)\n",
    "    print(tags_) #대괄호 제거\n",
    "\n",
    "    time.sleep(3)\n",
    "    driver.close()\n",
    "    \n",
    "    return str(restaurant_name), str(restaurant_adress), str(tags_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetResInfo_old(url):\n",
    "    print(url)\n",
    "    try:\n",
    "        driver = webdriver.Chrome()\n",
    "        #크롬 드라이버 설치 링크 : https:storage.googleapis.com/chrome-for-testing-public/127.0.6533.72/win64/chromedriver-win64.zip\n",
    "        #압축 해제 후, driver.exe는 실행파일과 같은 위치 혹은 하위에 존재해야 함\n",
    "        #사내망에선 드라이버의 물리적 위치 괄호 안에 지정해줘야 함\n",
    "    except SessionNotCreatedException as e:\n",
    "        print(\"SessionNotCreatedExceptions이 발생했습니다:\", str(e))\n",
    "        \n",
    "    #블로그 링크 하나씩 불러서 크롤링\n",
    "    tags = []\n",
    "    contents = []\n",
    "    restaurant_name = []\n",
    "    restaurant_address = []\n",
    "    \n",
    "    #블로그 링크 하나씩 불러오기\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "    #블로그 안 본문이 있는 iframe에 접근하기\n",
    "    driver.switch_to.frame(\"mainFrame\")\n",
    "\n",
    "    #본문 전체\n",
    "    try:\n",
    "        a = driver.find_element(By.CSS_SELECTOR,'div.se-main-container').text\n",
    "        contents.append(a)\n",
    "    # NoSuchElement 오류시 예외처리(구버전 블로그에 적용)\n",
    "    except NoSuchElementException:\n",
    "        a = driver.find_element(By.CSS_SELECTOR,'div#content-area').text\n",
    "        contents.append(a)\n",
    "    #print(본문: \\n', a)\n",
    "\n",
    "    #해시태그\n",
    "    # try:\n",
    "    #     t = driver.find_element(By.CSS_SELECTOR,'div.post-btn post_btn2')\n",
    "    #     tags.append(t)\n",
    "    # except NoSuchElementException:\n",
    "    #     print(\"해시태그를 찾을 수 없습니다.\")\n",
    "\n",
    "    # driver.quit() #창닫기\n",
    "    print(\"<<본문 크롤링이 완료되었습니다.>>\")\n",
    "    text = contents[0]\n",
    "    contents_list = text.split(\"\\n\")\n",
    "    print(contents_list)\n",
    "\n",
    "    print(\"<<본문의 장소 정보입니다.>>\")\n",
    "    try:\n",
    "        found = contents_list.index('© NAVER Corp.') ## 네이버 지도 전체가 위젯으로 넣어진 경우\n",
    "        restaurant_name.append(contents_list[found+1])\n",
    "        restaurant_address.append(contents_list[found+2])\n",
    "        print(restaurant_name)\n",
    "        print(restaurant_address)\n",
    "    except ValueError:\n",
    "        try : \n",
    "            found = contents_list.index('예약')\n",
    "            restaurant_name.append(contents_list[found-2]) ##네이버 지도 일부가 위젯으로 넣어지거나, \n",
    "            restaurant_address.append(contents_list[found-1])\n",
    "            print(restaurant_name)\n",
    "            print(restaurant_address)\n",
    "        except ValueError:\n",
    "            try : \n",
    "                found = contents_list.index('주소')\n",
    "                restaurant_name.append(contents_list[found-1]) ##지도가 본문에 첨부되지 않은 경우\n",
    "                restaurant_address.append(contents_list[found+1])\n",
    "                print(restaurant_name)\n",
    "                print(restaurant_address)\n",
    "            except ValueError:\n",
    "                print(\"장소 정보를 찾을 수 없습니다.\")\n",
    "                restaurant_name.append(\" \")\n",
    "                restaurant_address.append(\" \")\n",
    "                print(restaurant_name)\n",
    "                print(restaurant_address)\n",
    "        \n",
    "    try:\n",
    "        tag = [s for s in contents_list if \"#\" in s] \n",
    "        print(tag)\n",
    "        tags.append(tag)\n",
    "    except IndexError:\n",
    "            print(\"해시태그를 찾을 수 없습니다.\")\n",
    "\n",
    "    return restaurant_name[0], restaurant_address[0], str(tags)\n",
    "    driver.quit() #창닫기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetNaverBlog(url, crawler_date, crawler_time):\n",
    "    App = \"Naver Blog\"\n",
    "    data = []\n",
    "\n",
    "    #크롬 드라이버 연결\n",
    "    try:\n",
    "        driver = webdriver.Chrome()\n",
    "        #크롬 드라이버 설치 링크 : https:storage.googleapis.com/chrome-for-testing-public/127.0.6533.72/win64/chromedriver-win64.zip\n",
    "        #압축 해제 후, driver.exe는 실행파일과 같은 위치 혹은 하위에 존재해야 함\n",
    "        #사내망에선 드라이버의 물리적 위치 괄호 안에 지정해줘야 함\n",
    "    except SessionNotCreatedException as e:\n",
    "        print(\"SessionNotCreatedExceptions이 발생했습니다:\", str(e))\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # post_titles = driver.find_elements(By.CLASS_NAME,'title_post')\n",
    "\n",
    "    #크롤링 시작\n",
    "    print(\"-----네이버 블로그 - 맛집 포스트-----\")\n",
    "    for page in range(1,3): ##1~n-1 페이지까지. 5분 소요\n",
    "        driver.find_element(By.XPATH, '/html/body/ui-view/div/main/div[1]/div/section/div[2]/div[11]/span[{}]/a'.format(page)).click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        #포스트 제목\n",
    "        post_titles = driver.find_elements(By.CLASS_NAME,'title_post')\n",
    "\n",
    "        #포스트 url, 식당명, 식당주소\n",
    "        post_urls = driver.find_elements(By.CLASS_NAME,'desc_inner')\n",
    "        urls = []\n",
    "        # post_dates = []\n",
    "        name = []\n",
    "        address = []\n",
    "        tags = []\n",
    "\n",
    "        for i in post_urls :\n",
    "            href = i.get_attribute('href')\n",
    "            # print(href)\n",
    "            urls.append(href)\n",
    "        # print(urls)\n",
    "        \n",
    "        for url in urls :\n",
    "            res_name, res_address, tag = GetResInfo(url)\n",
    "            name.append(res_name)\n",
    "            address.append(res_address)\n",
    "            tags.append(tag)\n",
    "\n",
    "        # for post_title in post_titles:\n",
    "        #     print(post_title)\n",
    "        #     post_date = GetPostDate(post_title)\n",
    "        #     post_dates.append(post_date)\n",
    "            \n",
    "\n",
    "        for idx, post_title in enumerate(post_titles[9:]): ## Top 3 제거(제목너무 짧음), 공백 행 제거\n",
    "            title = post_title.text\n",
    "            line_data = []\n",
    "            line_data.append(App)\n",
    "            line_data.append(GetPostDate(title))\n",
    "            line_data.append(title)\n",
    "            line_data.append(urls[idx])\n",
    "            line_data.append(name[idx])\n",
    "            line_data.append(address[idx])\n",
    "            line_data.append(tags[idx])\n",
    "            line_data.append(crawler_time)\n",
    "            data.append(line_data)\n",
    "        \n",
    "    #데이터 프레임 생성\n",
    "    df = pd.DataFrame(data, columns=['앱', '포스트게시일', '포스트제목', 'URL', '음식점명', '음식점주소', '해시태그', '크롤링일시'])\n",
    "    df = df.astype({'포스트게시일': 'int64'})\n",
    "    df.index = df.index+1\n",
    "    df\n",
    "\n",
    "    #엑셀로 저장\n",
    "    df.to_excel('Results/FD_Crawling_Naver_Blog_{}.xlsx'.format(crawler_date), index=False)\n",
    "    time.sleep(3)\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 공정위 가맹사업정보제공시스템 정보공개서 크롤링 - 100개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetBusinessInfoSystem (url, crawler_date, crawler_time):\n",
    "    \n",
    "    try:\n",
    "        driver = webdriver.Chrome()\n",
    "        #크롬 드라이버 설치 링크 : https:storage.googleapis.com/chrome-for-testing-public/127.0.6533.72/win64/chromedriver-win64.zip\n",
    "        #압축 해제 후, driver.exe는 실행파일과 같은 위치 혹은 하위에 존재해야 함\n",
    "        #사내망에선 드라이버의 물리적 위치 괄호 안에 지정해줘야 함\n",
    "    except SessionNotCreatedException as e:\n",
    "        print(\"SessionNotCreatedExceptions이 발생했습니다:\", str(e))\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    #외식 업종, 100개씩 보기, 적용 조회\n",
    "    driver.find_element(By.XPATH, '/html/body/div[2]/div[3]/div/div[2]/div[2]/form/div[1]/fieldset/select[2]/option[2]').click()\n",
    "    driver.find_element(By.XPATH, '/html/body/div[2]/div[3]/div/div[2]/div[2]/form/div[1]/fieldset/input[2]').click()\n",
    "    driver.find_element(By.XPATH, '/html/body/div[2]/div[3]/div/div[2]/div[2]/form/div[2]/div/select/option[4]').click()\n",
    "    time.sleep(3)\n",
    "    driver.find_element(By.XPATH, '/html/body/div[2]/div[3]/div/div[2]/div[2]/form/div[2]/div/a').click() #적용 클릭\n",
    "    time.sleep(3)\n",
    "    table = driver.find_element(By.XPATH, '/html/body/div[2]/div[3]/div/div[2]/div[2]/form/table')\n",
    "    tbody = table.find_element(By.TAG_NAME, 'tbody')\n",
    "\n",
    "    i = 1\n",
    "    data = []\n",
    "    line_data = []\n",
    "    \n",
    "    wb = openpyxl.Workbook()\n",
    "    sheet = wb.active\n",
    "    sheet.append([\"번호\", \"상호\", \"영업표지\", \"대표자\",\"등록번호\", \"최초등록일\",\"업종\"])\n",
    "    # 번호, 상호, 영업표지, 대표자, 등록번호, 최초등록일, 업종\n",
    "\n",
    "    rows = tbody.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "    #테이블 파싱, 컬럼명 지정\n",
    "    for index, value in enumerate(rows):\n",
    "        Name = value.find_elements(By.TAG_NAME,\"td\")[1].text\n",
    "        Business = value.find_elements(By.TAG_NAME,\"td\")[2].text\n",
    "        Representative = value.find_elements(By.TAG_NAME,\"td\")[3].text\n",
    "        Registration_Number = value.find_elements(By.TAG_NAME,\"td\")[4].text\n",
    "        Init_Date = value.find_elements(By.TAG_NAME,\"td\")[5].text\n",
    "        Type = value.find_elements(By.TAG_NAME,\"td\")[6].text\n",
    "\n",
    "        sheet.append([i, Name, Business, Representative, Registration_Number, Init_Date, Type])\n",
    "        i +=1\n",
    "\n",
    "    for row in sheet.iter_rows(max_col=7, values_only=True):\n",
    "        print(row)\n",
    "        line_data.append(row)\n",
    "        data.append(line_data)\n",
    "\n",
    "    #saving to excel\n",
    "    # 정렬 전 저장\n",
    "    wb.save('./results/FD_Crawling_Business_Info_System_{}.xlsx'.format(crawler_date))\n",
    "\n",
    "    # 정렬 후 저장\n",
    "    xl = pd.ExcelFile('./Results/FD_Crawling_Business_Info_System_{}.xlsx'.format(crawler_date))\n",
    "    df = xl.parse(\"Sheet\")\n",
    "    df = df.sort_values(by=\"최초등록일\", ascending=False)\n",
    "    df = df.astype({'등록번호': 'int64'})\n",
    "    df.to_excel('./Results/FD_Crawling_Business_Info_System_{}.xlsx'.format(crawler_date), sheet_name=\"가맹사업정보\", columns=[\"번호\", \"상호\", \"영업표지\", \"대표자\", \"등록번호\", \"최초등록일\",\"업종\"],index=False)\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_excel(file_path, total_file, arch_file):\n",
    "\n",
    "    if os.path.isfile(total_file) :\n",
    "        print(\"기준 엑셀 파일에 병합합니다...\")\n",
    "        df1 = pd.read_excel(file_path)\n",
    "        df2 = pd.read_excel(total_file)\n",
    "        \n",
    "        df_total = pd.concat([df1,df2], ignore_index=False)\n",
    "        df_total.drop_duplicates(subset=None, keep='first',inplace=False, ignore_index=False)\n",
    "\n",
    "        if total_file == './Results/FD_Crawling_Business_Info_System_Total.xlsx':\n",
    "            df_total = df_total.drop('번호',axis=1)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    else:\n",
    "        print(\"파일이 존재하지 않습니다.\")\n",
    "    \n",
    "    df_total.to_excel(total_file, index=False)\n",
    "    print(\"병합을 완료하고 해당 파일을 보관합니다...\")\n",
    "    \n",
    "    import shutil\n",
    "    shutil.move(file_path, arch_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # 네이버 맛집 블로그 콘텐츠 크롤링\n",
    "    crawler_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "    crawler_date = datetime.datetime.now().strftime('%Y%m%d')\n",
    "    crawler_date = datetime.datetime.now().strftime('%Y%m%d')\n",
    "    print(\"Naver crawler_date : {}\".format(crawler_time))\n",
    "\n",
    "    naver_url = \"https://section.blog.naver.com/ThemePost.naver?directoryNo=29&activeDirectorySeq=3&currentPage=1\" #네이버 블로그 맛집 카테고리 메인 화면\n",
    "    GetNaverBlog(naver_url, crawler_date, crawler_time)\n",
    "\n",
    "    # 가맹사업정보시스템 크롤링\n",
    "    crawler_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "    crawler_date = datetime.datetime.now().strftime('%Y%m%d')\n",
    "    crawler_date = datetime.datetime.now().strftime('%Y%m%d')\n",
    "    print(\"가맹사업정보시스템 crawler_date : {}\".format(crawler_time))\n",
    "\n",
    "    business_info_system_url = \"https://franchise.ftc.go.kr/mnu/00013/program/userRqst/list.do\"\n",
    "    GetBusinessInfoSystem(business_info_system_url, crawler_date, crawler_time)\n",
    "\n",
    "    #결과 파일 병합, 저장\n",
    "    file_list_biz = glob.glob('./Results/FD_Crawling_Business_Info_System_2*.xlsx')\n",
    "    file_list_naver = glob.glob('./Results/FD_Crawling_Naver_Blog_2*.xlsx')\n",
    "    total_file_biz = './Results/FD_Crawling_Business_Info_System_Total.xlsx'\n",
    "    total_file_naver = './Results/FD_Crawling_Naver_Blog_Total.xlsx'\n",
    "    arch_file_biz = './Results/FD_Crawling_Business_Info_System_Archaive/{}'.format(file_list_biz[0].split('\\\\')[-1])\n",
    "    arch_file_naver = './Results/FD_Crawling_Naver_Blog_Archaive/{}'.format(file_list_naver[0].split('\\\\')[-1])\n",
    "\n",
    "    for file_path in file_list_biz:\n",
    "        print(file_path)\n",
    "        print(total_file_biz)\n",
    "        merge_excel(file_path, total_file_biz, arch_file_biz)\n",
    "\n",
    "    for file_path in file_list_naver:\n",
    "        print(file_path)\n",
    "        print(total_file_naver)\n",
    "        merge_excel(file_path, total_file_naver, arch_file_naver) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naver crawler_date : 2024-08-29 11:30\n",
      "-----네이버 블로그 - 맛집 포스트-----\n",
      "https://blog.naver.com/PostView.naver?blogId=winendine2017&logNo=223564698837&redirect=Dlog&widgetTypeCall=true&noTrackingCode=true&directAccess=false\n",
      "파브란트\n",
      "서울특별시 강남구 테헤란로 129 지하2층 B246호\n",
      "#강남n타워맛집, #강남역파스타, #강남역소개팅, #역삼파스타, #역삼맛집, #파브란트, #강남역데이트, #역삼역데이트, #강남데이트, #강남맛집, #강남파스타, #역삼역파스타, #파스타바, #역삼파스타바, #강남역파스타바\n",
      "https://blog.naver.com/PostView.naver?blogId=ggoulggoul&logNo=223564649477&redirect=Dlog&widgetTypeCall=true&noTrackingCode=true&directAccess=false\n",
      "영덕대게궁\n",
      "경상북도 영덕군 강구면 강구대게길 29 영덕대게궁\n",
      "#영덕대게맛집, #영덕강구항대게맛집, #강구항대게맛집, #강구항맛집, #영덕대게가격, #영덕대게궁가격, #영덕대게궁, #영덕강구항맛집, #영덕대게, #영덕가볼만한곳, #영덕대게거리, #대게코스요리, #영덕대게거리맛집, #대게宮, #대게궁\n",
      "https://blog.naver.com/PostView.naver?blogId=qnwkqortnn&logNo=223564770076&redirect=Dlog&widgetTypeCall=true&noTrackingCode=true&directAccess=false\n",
      "속초오징어어시장 강남역점\n",
      "서울특별시 강남구 강남대로78길 16 1층\n",
      "#강남역횟집, #강남역가성비횟집, #속초오징어어시장강남역, #강남회식장소추천\n",
      "https://blog.naver.com/PostView.naver?blogId=s2ll27&logNo=223564642896&redirect=Dlog&widgetTypeCall=true&noTrackingCode=true&directAccess=false\n",
      "부산횟집\n",
      "강원특별자치도 원주시 만대공원길 56\n",
      "#원주무실동맛집, #원주점심맛집, #원주물회맛집, #원주부산횟집, #원주맛집추천, #원주무실동맛집추천\n",
      "https://blog.naver.com/PostView.naver?blogId=enviableb&logNo=223564632129&redirect=Dlog&widgetTypeCall=true&noTrackingCode=true&directAccess=false\n",
      "마구로참치\n",
      "서울특별시 용산구 한강대로 271\n",
      "#숙대입구역맛집, #마구로참치, #숙대입구맛집, #남영역맛집, #갈월동맛집, #용산참치, #남영동맛집, #숙대입구횟집, #남영역횟집, #용산횟집, #용산룸식당, #서울참치맛집\n",
      "https://blog.naver.com/PostView.naver?blogId=suzy_blog&logNo=223564812454&redirect=Dlog&widgetTypeCall=true&noTrackingCode=true&directAccess=false\n",
      "우대포 강남역점\n",
      "서울특별시 강남구 강남대로94길 11 1층\n",
      "#역삼문화공원제1호공영주차장, #우대포, #강남역맛집, #강남역고기집, #역삼동맛집, #강남역회식, #강남역소고기, #강남역고기, #강남역모임, #강남역저녁, #강남역11번출구맛집\n",
      "https://blog.naver.com/PostView.naver?blogId=omytheo&logNo=223564807189&redirect=Dlog&widgetTypeCall=true&noTrackingCode=true&directAccess=false\n",
      "소오산\n",
      "경기도 오산시 내삼미로79번길 26 107, 108호\n",
      "#소오산, #오산고기맛집, #오산대역맛집, #소갈비살, #오산소갈비살, #오산모임, #오산회식, #가성비회식장소, #숯불소고기\n",
      "https://blog.naver.com/PostView.naver?blogId=hahadanro&logNo=223562750525&redirect=Dlog&widgetTypeCall=true&noTrackingCode=true&directAccess=false\n",
      "오남매솥밥\n",
      "경기도 의정부시 오목로225번길 23-3 1층 오남매클라스\n",
      "#오남매솥밥, #민락동맛집, #한식맛집, #의정부맛집, #의정부김치찌개, #김치찌개, #통삽겹김치찜\n",
      "https://blog.naver.com/PostView.naver?blogId=ddomuz&logNo=223564273757&redirect=Dlog&widgetTypeCall=true&noTrackingCode=true&directAccess=false\n",
      "동천홍 봉담점\n",
      "경기도 화성시 봉담읍 삼천병마로 1079-12\n",
      "#동천홍, #동천홍봉담점, #왕림휴게소맛집, #봉담중국집, #봉담짬뽕맛집, #봉담마라짬뽕, #봉담짜장면, #봉담중식당, #봉담가족모임\n",
      "https://blog.naver.com/PostView.naver?blogId=ykheeee9500&logNo=223564513957&redirect=Dlog&widgetTypeCall=true&noTrackingCode=true&directAccess=false\n",
      "미면정 양재본점\n",
      "서울특별시 강남구 남부순환로365길 22 오이빌딩 2층\n",
      "#양재역맛집, #양재역맛집미면정, #미면정양재본점, #만두칼국수맛집, #한국음식장인이만드는미면정\n",
      "https://blog.naver.com/PostView.naver?blogId=kcy2736&logNo=223564554138&redirect=Dlog&widgetTypeCall=true&noTrackingCode=true&directAccess=false\n",
      "트롬바커피\n",
      "서울특별시 강남구 선릉로126길 12 1층\n",
      "#서이추환영, #삼성동카페, #강남구청대저트카페, #삼성동디저트카페\n",
      "https://blog.naver.com/PostView.naver?blogId=maboo37&logNo=223564409145&redirect=Dlog&widgetTypeCall=true&noTrackingCode=true&directAccess=false\n",
      "본문내 지도 위젯이 없습니다.\n",
      "#협찬, #요거트아이스크림의정석, #요거트아이스크림, #생과일아이스크림, #요거트, #그릭요거트, #그릭요거트전문점, #요거트아이스크림전문점, #카페프랜차이즈, #요거트프랜차이즈, #yogurt, #greek, #디저트, #디저트맛집, #자사앱, #앱, #요아정앱, #할인쿠폰\n",
      "https://blog.naver.com/PostView.naver?blogId=1115hq&logNo=223564798254&redirect=Dlog&widgetTypeCall=true&noTrackingCode=true&directAccess=false\n",
      "고기삼촌\n",
      "강원특별자치도 원주시 시청로 24 105,106호\n",
      "#원주한우맛집, #원주시청맛집\n",
      "https://blog.naver.com/PostView.naver?blogId=sophie242&logNo=223561781307&redirect=Dlog&widgetTypeCall=true&noTrackingCode=true&directAccess=false\n",
      "한드케이크\n",
      "서울특별시 노원구 공릉로58다길 5 B1층 한드케이크\n",
      "#노원주문제작케이크, #노원레터링케이크, #하계역케이크, #도시락케이크, #한드케이크, #레터링케이크디자인, #주문제작케이크, #주문제작케이크도안\n",
      "https://blog.naver.com/PostView.naver?blogId=buzafama&logNo=223561930435&redirect=Dlog&widgetTypeCall=true&noTrackingCode=true&directAccess=false\n",
      "옥상휴게소\n",
      "경기도 부천시 원미구 부천로 148 1층 전체\n",
      "#부천캠핑식당, #부천바베큐맛집, #부천캠핑바베큐, #부천캠핑바베큐식당\n",
      "https://blog.naver.com/PostView.naver?blogId=ejr8806&logNo=223564731432&redirect=Dlog&widgetTypeCall=true&noTrackingCode=true&directAccess=false\n",
      "한주\n",
      "대구광역시 수성구 달구벌대로512길 10 1층 한주\n",
      "#대구수성구술집, #수성구술집, #한주, #범어동한주, #범어동맛집\n",
      "https://blog.naver.com/PostView.naver?blogId=darkyoon85&logNo=223564335342&redirect=Dlog&widgetTypeCall=true&noTrackingCode=true&directAccess=false\n",
      "챠오바라이트 판교점\n",
      "경기도 성남시 분당구 대왕판교로 660 유스페이스1 1층 125호 챠오바라이트\n",
      "#판교맛집, #판교술집, #하이네켄, #하이네켄생맥주, #하이네켄생맥주맛집, #챠오바라이트, #생맥주, #첫모금, #맛집추천, #광고\n",
      "https://blog.naver.com/PostView.naver?blogId=zephyr122059&logNo=223559250507&redirect=Dlog&widgetTypeCall=true&noTrackingCode=true&directAccess=false\n",
      "국숯집 연남점\n",
      "서울특별시 마포구 동교로34길 21 우측 지층\n",
      "#남발게님, #국숯집, #연남동국숯집, #남발카세, #해산물잔치, #국숯집팝업, #남발게님팝업, #연남동남발카세팝업\n",
      "https://blog.naver.com/PostView.naver?blogId=chuchus1216&logNo=223564623754&redirect=Dlog&widgetTypeCall=true&noTrackingCode=true&directAccess=false\n",
      "녹두꽃\n",
      "전북특별자치도 전주시 완산구 팔달로 106-1 한옥마을 주차장 안쪽 1층\n",
      "#전주한옥마을한정식맛집, #녹두꽃, #전주녹두꽃, #전주한옥마을한정식, #전주한정식맛집녹두꽃, #전주한옥마을한정식맛집녹두꽃, #전주한정식맛집, #전주한정식, #전주맛집, #전주한옥마을, #전주한옥마을맛집, #한옥마을맛집, #한옥마을한정식맛집, #한옥마을한정식, #전주한상, #전주한상차림, #한정식맛집, #전주, #맛집, #전주건강한맛집\n",
      "https://blog.naver.com/PostView.naver?blogId=rapunzelli3&logNo=223564429953&redirect=Dlog&widgetTypeCall=true&noTrackingCode=true&directAccess=false\n",
      "중화복춘 살롱 시그니처\n",
      "서울특별시 마포구 연남로 10 1층\n",
      "#중화복춘, #중화복춘살롱시그니처, #남복춘쉐프, #연남데이트, #연남동중식당, #홍대중식당, #홍대회식, #연남동회식, #홍대미쉐린가이드, #연남동미쉐린가이드, #연남동맛집\n",
      "가맹사업정보시스템 crawler_date : 2024-08-29 11:37\n",
      "('번호', '상호', '영업표지', '대표자', '등록번호', '최초등록일', '업종')\n",
      "(1, '(주)비엔에프시리즈', '버거앤프라이즈(Burger&Friez)', '유용호', '20161308', '2016.12.30', '기타 외식')\n",
      "(2, '블루빈컴퍼니(주)', '라떼킹(Latteking)', '김태준', '20110100073', '2011.03.22', '커피')\n",
      "(3, '저스트카츠', '저스트카츠', '김성훈', '20240528', '2024.04.11', '일식')\n",
      "(4, '(주)카페코지', '코지스낵랩', '최석민,우지연', '20240452', '2024.03.25', '커피')\n",
      "(5, '(주)카페코지', '카페코지', '최석민외 1', '20191245', '2019.11.25', '커피')\n",
      "(6, '88그린푸드(주)', '88노가리', '남두산', '20220923', '2022.09.06', '주점')\n",
      "(7, '(주)스타푸드코리아', '킹스타치킨', '이병철', '20190614', '2019.06.28', '치킨')\n",
      "(8, '(주)스타푸드코리아', '킹스타피자', '이병철', '20150271', '2015.03.20', '피자')\n",
      "(9, '(주)대만족', '대만족', '구본무', '20200633', '2020.05.25', '한식')\n",
      "(10, '㈜비엔피컴퍼니', '노비커피(Nobby COFFEE)', '배진윤', '20241186', '2024.08.28', '커피')\n",
      "(11, '타펠룬데(TAFELRUNDE)', '타펠룬데(TAFELRUNDE)', '유한솔', '20241188', '2024.08.28', '서양식')\n",
      "(12, '(주)에프엔아이컴퍼니', '윤반장 역전오리', '윤희재', '20241184', '2024.08.28', '한식')\n",
      "(13, '(주)카멜레온푸드', 'PJ피자', '진명훈, 박천호', '20180959', '2018.09.14', '피자')\n",
      "(14, '이천억조개구이', '더땅피자치킨', '유재상', '20214834', '2021.11.15', '피자')\n",
      "(15, '이천억조개구이', '탄불이갈비', '유재상', '20214757', '2021.11.12', '기타 외식')\n",
      "(16, '이천억조개구이', '여몽고기박사', '유재상', '20214837', '2021.11.15', '한식')\n",
      "(17, '이천억조개구이', '유달구조개찜&고기한판', '유재상', '20215409', '2021.11.17', '한식')\n",
      "(18, '이천억조개구이', '유달구아구찜', '유재상', '20215065', '2021.11.16', '한식')\n",
      "(19, '이천억조개구이', '유달구수산물직판장', '유재상', '20214844', '2021.11.15', '한식')\n",
      "(20, '이천억조개구이', '이천억 조개구이와 고기', '유재상', '20214055', '2021.11.04', '한식')\n",
      "(21, '(주)보우앤파트너스', '미소야', '이진규', '20080100430', '2008.09.01', '일식')\n",
      "(22, '김뚜껑푸드', '김뚜껑 부대찌개', '김도헌', '20220890', '2022.08.26', '한식')\n",
      "(23, '오육', '오육', '김기범', '20221127', '2022.10.25', '한식')\n",
      "(24, '(주)샐러디', '샐러디', '이건호, 안상원', '20150828', '2015.08.28', '기타 외식')\n",
      "(25, '(주)오니규', '오니기리와이규동', '이명훈', '20100100210', '2010.04.30', '기타 외식')\n",
      "(26, '(주)음식의전당', '동태랑', '김보곤', '20201455', '2020.11.03', '한식')\n",
      "(27, '(주)피앤에프', '팔공티', '김종현', '20171075', '2017.09.08', '음료 (커피 외)')\n",
      "(28, '(주)건양물산', '건어무리', '오동현', '20230989', '2023.07.10', '기타 외식')\n",
      "(29, '(주)에프씨천상', '이태원천상', '박순임', '20100100171', '2010.04.09', '일식')\n",
      "(30, '(주)에프씨천상', '우동텐', '박순임', '20110100088', '2011.04.01', '기타 외식')\n",
      "(31, '(주)에프씨천상', '돈까스잔치', '박순임', '20170686', '2017.06.15', '한식')\n",
      "(32, '(주)이루에프씨', '통파이브', '이문기', '20120100422', '2012.08.22', '주점')\n",
      "(33, '(주)이루에프씨', '땡큐맘치킨', '이문기', '20190774', '2019.07.31', '치킨')\n",
      "(34, '㈜케이알지', '당신이선택한인생치킨', '권이형', '20231459', '2023.10.05', '치킨')\n",
      "(35, '(주)비엔에프시리즈', '치킨앤프라이즈119', '유용호', '20240022', '2024.01.02', '기타 외식')\n",
      "(36, '(주)아티스티', '아티스티', '김정동', '20190407', '2019.05.07', '음료 (커피 외)')\n",
      "(37, '씨엘카이로스(주)', '완백부대찌개', '조용훈, 이승하', '20170348', '2017.03.09', '기타 외식')\n",
      "(38, '(주)이루에프씨', '바른치킨', '이문기', '20150930', '2015.09.25', '치킨')\n",
      "(39, '(주)도스타코스', '도스타코스', '박성준', '20100100024', '2010.01.11', '기타 외국식')\n",
      "(40, '(주)낭만에프앤비', '낭만낙곱새', '김승현', '20220485', '2022.06.08', '한식')\n",
      "(41, '(주)사보르웨이', '스시웨이', '한종대', '20130100040', '2013.01.30', '일식')\n",
      "(42, '(주)쿠시마사', '만소당', '구설아', '20240402', '2024.03.14', '일식')\n",
      "(43, '(주)쿠시마사', '쿠시마사', '구설아', '20190246', '2019.03.27', '일식')\n",
      "(44, '(주)에스엘투', '파라노이드', '홍병수', '20211814', '2021.08.09', '커피')\n",
      "(45, '(주)옳음', '청담동샤브', '원영기', '20212287', '2021.09.27', '한식')\n",
      "(46, '(주)하백', '배터지는한우', '김동수', '20231022', '2023.07.14', '한식')\n",
      "(47, '(주)유니쉐프딜리버리', '삼장샤브칼국수', '최윤혁,오경열', '20240194', '2024.02.06', '한식')\n",
      "(48, '(주)유니쉐프', '황금 라멘', '최윤혁 오경열', '20201806', '2020.12.17', '일식')\n",
      "(49, '(주)커스텀커피', '커스텀커피', '오병석', '20201631', '2020.12.01', '커피')\n",
      "(50, '(주)케이배기에프앤비', '동성로왕찹쌀꽈배기', '조정범', '20214201', '2021.11.05', '제과제빵')\n",
      "(51, '오빠곱창대전본점', '오빠곱창', '이영길', '20241183', '2024.08.27', '한식')\n",
      "(52, '겐로쿠우동', '겐로쿠우동', '이강우', '20110100199', '2011.06.08', '일식')\n",
      "(53, '잠실꽃낙지', '꽃낙지', '왕복섭', '20220833', '2022.08.17', '한식')\n",
      "(54, '허니라이프', '허니홈비', '송량근', '20215488', '2021.11.17', '아이스크림/빙수')\n",
      "(55, '㈜유진에프앤비', '빵샘베이커리', '최상근', '20220842', '2022.08.17', '제과제빵')\n",
      "(56, '한끼닭칼국수', '한끼닭칼국수', '이경자', '20220424', '2022.05.18', '한식')\n",
      "(57, '(주)이독도참치유통', '참치학교', '천인옥', '20211556', '2021.07.12', '기타 외식')\n",
      "(58, '(주)몬쉘코리아', '몽슈슈', '김수근', '20190689', '2019.07.15', '기타 외식')\n",
      "(59, '배달더쿡', '원래는 치킨집을 할려고 했었다', '김준혁', '20190838', '2019.08.16', '분식')\n",
      "(60, '배달더쿡', '젓가락질 잘해야만 밥을 먹나요', '김준혁', '20211203', '2021.05.17', '한식')\n",
      "(61, '(주)메종이츠', '피자웨이브', '양기원', '20211569', '2021.07.14', '피자')\n",
      "(62, '(주)메종이츠', '타코아찌 타코야끼전문점', '양기원', '20212274', '2021.09.27', '일식')\n",
      "(63, '(주)메종이츠', '마몽로제떡볶이', '양기원', '20210819', '2021.03.23', '분식')\n",
      "(64, '(주)메종이츠', '정직김치찜', '양기원', '20213988', '2021.11.03', '한식')\n",
      "(65, '(주)메종이츠', '도깨비카레', '양기원', '20213990', '2021.11.03', '기타 외식')\n",
      "(66, '(주)메종이츠', '최강곱도리', '양기원', '20213991', '2021.11.03', '한식')\n",
      "(67, '(주)하율홀딩스', '무모한 초밥', '안정윤, 김성수', '20201327', '2020.10.08', '일식')\n",
      "(68, '(주)푸드로', '돈애반해', '김시헌, 김한구', '20201597', '2020.11.26', '한식')\n",
      "(69, '(주)한옥집에이치큐', '한옥집김치찜', '이재규', '20181164', '2018.11.15', '한식')\n",
      "(70, '(주)제이엔에이치나인스', '만고쿠', '정주호', '20201552', '2020.11.18', '일식')\n",
      "(71, '(주)에스앤씨세인', '더벤티', '최준경,박수암,강삼남', '20140722', '2014.08.12', '커피')\n",
      "(72, '차알(주)', '차알(Cha’R)', '차주민', '20220835', '2022.08.17', '중식')\n",
      "(73, '(주)별에프앤비', '나는자연닭이다', '김기혁', '20210674', '2021.03.10', '치킨')\n",
      "(74, '(주)석봉토스트', '석봉토스트', '김석봉', '20080100666', '2008.11.05', '패스트푸드')\n",
      "(75, '엘앤에스', '라이스투 미튜', '김기광', '20180621', '2018.07.05', '한식')\n",
      "(76, '(주)명가참푸드', '명가통닭', '박용암', '20200798', '2020.06.30', '치킨')\n",
      "(77, '제이에스(J.S)패밀리', '이가탕수6', '이정석', '20214473', '2021.11.09', '중식')\n",
      "(78, '골든키본', '두근두근소담마루', '송태융', '20191359', '2019.12.17', '기타 외국식')\n",
      "(79, '(주)미가랑푸드', \"쉐프스 그릴(Chef's grill)\", '김영숙', '20215459', '2021.11.17', '서양식')\n",
      "(80, '(주)민성', '카페인사계(Cafe in Sagye)', '양성환', '20221335', '2022.11.23', '커피')\n",
      "(81, '(주)느리게걷기', '스위트99', '서은진', '20212158', '2021.09.02', '기타 외식')\n",
      "(82, '(주)태성에프앤비', '고랭지 태백집', '강성호', '20230865', '2023.06.16', '한식')\n",
      "(83, '카페코나퀸즈(주)', '카페코나퀸즈', '한림', '20150515', '2015.06.19', '커피')\n",
      "(84, '주인프래너스(주)', '간이역', '황병훈', '20080100201', '2008.08.06', '주점')\n",
      "(85, '킹스빈', '킹스빈', '어대영', '20180295', '2018.03.23', '커피')\n",
      "(86, '본아이에프(주)', '본도시락', '이진희,이성진', '20100100482', '2010.10.08', '한식')\n",
      "(87, '과일욤', '과일욤', '전상민', '20241175', '2024.08.26', '음료 (커피 외)')\n",
      "(88, '메가컴퍼니', '코코마라', '이영준', '20241179', '2024.08.26', '중식')\n",
      "(89, '지몽', '지몽', '김준', '20241176', '2024.08.26', '한식')\n",
      "(90, '리라버거', '리라버거', '정우정', '20241168', '2024.08.26', '패스트푸드')\n",
      "(91, '텬고', '여름이네', '민선기', '20241165', '2024.08.26', '분식')\n",
      "(92, '착한막창', '착한막창', '도경무', '20241182', '2024.08.26', '한식')\n",
      "(93, '양림온칼', '양림온칼', '노우성', '20241177', '2024.08.26', '한식')\n",
      "(94, '영화당', '영화당', '최세련', '20241178', '2024.08.26', '한식')\n",
      "(95, '(주)멋진인생', '라쿵푸샤브훠궈 앤 마라탕', '박선주', '20241180', '2024.08.26', '중식')\n",
      "(96, '(주)멋진인생', '라쿵푸마라탕', '박선주', '20241181', '2024.08.26', '중식')\n",
      "(97, '(주)크레오코리아', '파일론 익스프레스', '최현우', '20241169', '2024.08.26', '서양식')\n",
      "(98, '(주)크레오코리아', '파일론 샵인샵', '최현우', '20241170', '2024.08.26', '서양식')\n",
      "(99, '통큰감자탕', '통큰감자탕', '심재춘', '20241174', '2024.08.26', '한식')\n",
      "(100, '본아이에프(주)', '멘지', '이진희,이성진', '20231129', '2023.08.04', '일식')\n",
      "./Results\\FD_Crawling_Business_Info_System_20240829.xlsx\n",
      "./Results/FD_Crawling_Business_Info_System_Total.xlsx\n",
      "기준 엑셀 파일에 병합합니다...\n",
      "병합을 완료하고 해당 파일을 보관합니다...\n",
      "./Results\\FD_Crawling_Naver_Blog_20240829.xlsx\n",
      "./Results/FD_Crawling_Naver_Blog_Total.xlsx\n",
      "기준 엑셀 파일에 병합합니다...\n",
      "병합을 완료하고 해당 파일을 보관합니다...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
