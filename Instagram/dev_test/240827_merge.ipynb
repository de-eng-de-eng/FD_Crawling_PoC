{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04bcb33e-52bf-4e65-a02b-b854d2d8292a",
   "metadata": {},
   "source": [
    "##### 인스타 해시태그 크롤링 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60194217-ea30-4c9a-84b8-98203b62cbf0",
   "metadata": {},
   "source": [
    "## 1. 인스타그램 특정 >> 게시글(URL) <<데이터 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13652ed-f858-43ce-afd8-9c33b338cb66",
   "metadata": {},
   "source": [
    "##### [조건] \n",
    "#####  1. 로그인 X\n",
    "#####  2. 특정 게시글(URL) 대상\n",
    "#####  3. 계정명, 좋아요 수, 해시태그, 본문 벌크, 게시 날짜, 추출 날짜, 결과 csv 저장(계정명.csv)\n",
    "##### [문제점]\n",
    "##### 1. 좋아요 수 집계 불가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d036f22-5565-45d4-8b97-e55ba8258791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to instagram_post_data.csv: {'account_name': '@sh.cookkook', 'likes': 'N/A', 'hashtags': '#입분식가정집, #송파맛집, #송리단길, #송리단길맛집, #잠실맛집, #즉석떡볶이, #즉떡', 'post_text': 'sh.cookkook\\n줄서는식당에도 나온 즉떡?\\n\\n어릴 적부터 주구장창 먹고자란 저란 아이..\\n여기 즉떡은 육수+특제 소스로 찐한맛이라\\n자극적인 맛 러버들이 특히 좋아할 곳>.<\\n\\n그리고 우삼겹이나 대창 추가도 할 수 있어\\n특별하게 느껴졌고, 저는 이번엔 계란이랑\\n어떡만 추가했어요!(어묵 안에 떡이 있음)\\n\\n기본으로만 먹어도 양 충분했고 넘모넘모\\n맛있음ㅜ 치즈까지 뿌려서 치즈길 만들면\\n더 극락인 거 비밓,,>.<\\n\\n📍입분식가정집\\n📍서울 송파구 오금로18길 10 2층\\n📍매일 11:30-21:00\\n\\n맛집 콕 찝어서 알려줄게요! 신콕💖\\n@sh.cookkook\\n@sh.cookkook\\n@sh.cookkook\\n-\\n-\\n-\\n#입분식가정집 #송파맛집 #송리단길 #송리단길맛집 #잠실맛집 #즉석떡볶이 #즉떡\\n16시간', 'post_date': '2024-08-26 08:33:29', 'crawl_time': '2024-08-27 10:03:38', 'post_url': 'https://www.instagram.com/reel/C_IGZmRyUU9/?utm_source=ig_web_copy_link&igsh=MzRlODBiNWFlZA=='}\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# 1. 웹드라이버 설정 및 페이지 이동\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "# 인스타그램 릴스 URL\n",
    "url = \"https://www.instagram.com/reel/C_IGZmRyUU9/?utm_source=ig_web_copy_link&igsh=MzRlODBiNWFlZA==\"\n",
    "driver.get(url)\n",
    "time.sleep(10)  # 페이지 로드 대기\n",
    "\n",
    "# 2. 데이터 추출\n",
    "# 계정명 추출\n",
    "try:\n",
    "    account_name = driver.find_element(By.XPATH, '//a[contains(@class, \"notranslate\")]').text\n",
    "except:\n",
    "    account_name = \"N/A\"\n",
    "\n",
    "\n",
    "# 좋아요 수 추출\n",
    "try:\n",
    "    # 좋아요 수가 포함된 span 요소를 찾습니다.\n",
    "    likes_element = driver.find_element(By.XPATH, '//div[contains(text(), \"likes\")]')\n",
    "    likes = likes_element.text.split(' ')[0]  # 'likes' 텍스트 앞의 숫자만 추출\n",
    "except:\n",
    "    likes = \"N/A\"\n",
    "    \n",
    "\n",
    "# 해시태그 추출\n",
    "try:\n",
    "    hashtags = [tag.text for tag in driver.find_elements(By.XPATH, '//a[contains(@href, \"/explore/tags/\")]')]\n",
    "    hashtags = hashtags[:10]  # 상위 10개 해시태그만 가져오기\n",
    "except:\n",
    "    hashtags = []\n",
    "\n",
    "# 본문 텍스트 추출\n",
    "try:\n",
    "    post_text = driver.find_element(By.XPATH, '//div[@class=\"_a9zr\"]').text\n",
    "except:\n",
    "    post_text = \"\"\n",
    "\n",
    "# 게시 날짜 추출\n",
    "try:\n",
    "    post_date_element = driver.find_element(By.XPATH, '//time')\n",
    "    post_date = post_date_element.get_attribute('datetime')\n",
    "    post_date = datetime.strptime(post_date, \"%Y-%m-%dT%H:%M:%S.%fZ\").strftime(\"%Y-%m-%d %H:%M:%S\")  # ISO 형식을 datetime으로 변환\n",
    "except:\n",
    "    post_date = \"N/A\"\n",
    "\n",
    "# 현재 크롤링 시간\n",
    "crawl_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# 3. 결과 출력 및 CSV 저장\n",
    "data = {\n",
    "    'account_name': account_name,\n",
    "    'likes': likes,\n",
    "    'hashtags': ', '.join(hashtags),\n",
    "    'post_text': post_text,\n",
    "    'post_date': post_date,\n",
    "    'crawl_time': crawl_time,\n",
    "    'post_url': url\n",
    "}\n",
    "\n",
    "# CSV 저장\n",
    "df = pd.DataFrame([data])\n",
    "df.to_csv('{}.csv'.format(account_name), index=False)\n",
    "\n",
    "print(f\"Data saved to instagram_post_data.csv: {data}\")\n",
    "\n",
    "\n",
    "# 드라이버 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b229c9bc-bf33-46e1-afd0-28a72cc624e7",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6d5a85-43bd-44f2-a81d-6f1b967581c4",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9e04e8-f3ae-4f9b-a953-af5628c48256",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad51898-52ce-465c-97d1-fefd0497f31a",
   "metadata": {},
   "source": [
    "## 2. 인스타그램 특정 >> 계정 << 데이터 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deac3f40-5ce7-4421-a2a2-22415e16436a",
   "metadata": {},
   "source": [
    "##### [조건] \n",
    "#####  1. 로그인 O (비즈니스계정)\n",
    "#####  2. 특정 계정 대상\n",
    "#####  3. 계정명, 좋아요 수, 해시태그, 본문 벌크, 게시 날짜, 추출 날짜, 결과 csv 저장_(계정명.csv-추출)\n",
    "##### [문제점]\n",
    "#####  1. csv 파일로 떨궈지나, 데이터 추출이 안됌\n",
    "#####  2. 이유를 모르겠음 ㅠㅠ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f40a22c8-4c8b-4d8d-bb8c-899d52b23873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to seoul__nadri.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# 데이터 저장을 위한 리스트 초기화\n",
    "account_name_list = []\n",
    "likes_list = []\n",
    "hashtags_list = []\n",
    "post_text_list = []\n",
    "post_date_list = []\n",
    "crawl_time_list = []\n",
    "post_url_list = []\n",
    "\n",
    "# 1. 웹드라이버 설정 및 인스타그램 로그인\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "# 인스타그램 로그인 페이지로 이동\n",
    "driver.get(\"https://www.instagram.com/accounts/login/\")\n",
    "time.sleep(5)  # 페이지 로드를 기다림\n",
    "\n",
    "# 로그인 정보 입력\n",
    "username = \"snsdkf1234@naver.com\"\n",
    "password = \"wel1234\"\n",
    "\n",
    "driver.find_element(By.NAME, \"username\").send_keys(username)\n",
    "driver.find_element(By.NAME, \"password\").send_keys(password)\n",
    "driver.find_element(By.XPATH, '//*[@id=\"loginForm\"]/div/div[3]/button').click()\n",
    "time.sleep(5)  # 로그인 후 대기\n",
    "\n",
    "# 2. 특정 계정으로 이동\n",
    "account_name = \"seoul__nadri\"  # 크롤링할 계정의 사용자 이름\n",
    "driver.get(f\"https://www.instagram.com/{account_name}/\")\n",
    "time.sleep(5)\n",
    "\n",
    "# 게시물 URL 리스트 가져오기\n",
    "post_elements = driver.find_elements(By.XPATH, '//article//a')\n",
    "post_urls = [element.get_attribute('href') for element in post_elements]\n",
    "\n",
    "# URL 출력 및 각 게시물에 대한 정보 추출\n",
    "for url in post_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # 페이지 로드 대기\n",
    "\n",
    "    # 계정명 추출\n",
    "    try:\n",
    "       account_name = driver.find_element(By.XPATH, '//a[contains(@class, \"notranslate\")]').text\n",
    "    except:\n",
    "       account_name = \"N/A\"\n",
    "\n",
    "    # 좋아요 수 추출\n",
    "    try:\n",
    "        likes_element = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//div[contains(text(), \"likes\")]'))\n",
    "        )\n",
    "        likes = likes_element.text.split(' ')[0]  # 'likes' 텍스트 앞의 숫자만 추출\n",
    "    except:\n",
    "        likes = \"N/A\"\n",
    "    \n",
    "    # 해시태그 추출\n",
    "    try:\n",
    "        hashtags = [tag.text for tag in driver.find_elements(By.XPATH, '//a[contains(@href, \"/explore/tags/\")]')]\n",
    "        hashtags = hashtags[:10]  # 상위 10개 해시태그만 가져오기\n",
    "    except:\n",
    "        hashtags = []\n",
    "    \n",
    "    # 본문 텍스트 추출\n",
    "    try:\n",
    "        post_text = driver.find_element(By.XPATH, '//div[@class=\"_a9zr\"]').text\n",
    "    except:\n",
    "        post_text = \"\"\n",
    "    \n",
    "    # 게시 날짜 추출\n",
    "    try:\n",
    "        post_date_element = driver.find_element(By.XPATH, '//time')\n",
    "        post_date = post_date_element.get_attribute('datetime')\n",
    "        post_date = datetime.strptime(post_date, \"%Y-%m-%dT%H:%M:%S.%fZ\").strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    except:\n",
    "        post_date = \"N/A\"\n",
    "    \n",
    "    # 현재 크롤링 시간\n",
    "    crawl_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # 데이터 리스트에 추가\n",
    "    account_name_list.append(account_name)\n",
    "    likes_list.append(likes)\n",
    "    hashtags_list.append(', '.join(hashtags))\n",
    "    post_text_list.append(post_text)\n",
    "    post_date_list.append(post_date)\n",
    "    crawl_time_list.append(crawl_time)\n",
    "    post_url_list.append(url)\n",
    "\n",
    "    print(f\"Crawled: {url}\")\n",
    "\n",
    "# 4. 데이터프레임 생성 및 CSV 저장\n",
    "data = {\n",
    "    'account_name': account_name_list,\n",
    "    'likes': likes_list,\n",
    "    'hashtags': hashtags_list,\n",
    "    'post_text': post_text_list,\n",
    "    'post_date': post_date_list,\n",
    "    'crawl_time': crawl_time_list,\n",
    "    'post_url': post_url_list\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# CSV 파일로 저장\n",
    "df.to_csv(f'{account_name}.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Data saved to {account_name}.csv\")\n",
    "\n",
    "# 드라이버 종료\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8408c1ac-af91-43f6-8ca5-bbd245f59629",
   "metadata": {},
   "source": [
    "## 계정의 URL 긁어오는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82ca16fe-e93f-4df2-a544-3a02668ec401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.instagram.com/seoul__nadri/p/C_H75-ZBrd5/', 'https://www.instagram.com/seoul__nadri/p/C_HftwGzW5A/', 'https://www.instagram.com/seoul__nadri/p/C_HeAKSz27s/', 'https://www.instagram.com/seoul__nadri/p/C_Fyj_KTjcN/', 'https://www.instagram.com/seoul__nadri/p/C_CFL75zAIb/', 'https://www.instagram.com/seoul__nadri/p/C-_zPbbT0hj/', 'https://www.instagram.com/seoul__nadri/p/C-9NLF8T6EO/', 'https://www.instagram.com/seoul__nadri/p/C-6lGXbzKOP/', 'https://www.instagram.com/seoul__nadri/p/C-4gcOBT2Sc/', 'https://www.instagram.com/seoul__nadri/reel/C-4TpS0yLzJ/', 'https://www.instagram.com/seoul__nadri/p/C-4DIEVT_wx/', 'https://www.instagram.com/seoul__nadri/p/C-16RWghNvs/']\n"
     ]
    }
   ],
   "source": [
    "post_elements = driver.find_elements(By.XPATH, '//article//a')\n",
    "post_urls = [element.get_attribute('href') for element in post_elements]\n",
    "print(post_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801ad36d-f4e9-4a54-be0d-4bb2a57105ff",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa44c19f-6a86-4c25-a7cf-897be68f7670",
   "metadata": {},
   "source": [
    "## 1. URL 추출 코드 \n",
    "### [조건]\n",
    "1. 로그인 O\n",
    "2. 특정 계정 대상\n",
    "3. 계정명, 좋아요 수, 해시태그, 본문 벌크, 게시 날짜, 추출 날짜, 결과 csv 저장(계정명.csv)\n",
    "### [문제점]\n",
    "1. 좋아요 수 집계 불가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75546b1b-e977-4d9d-ab6e-53f86ab06ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.instagram.com/sh.cookkook/reel/C_J_jvLSOzd/', 'https://www.instagram.com/sh.cookkook/reel/C_IGZmRyUU9/', 'https://www.instagram.com/sh.cookkook/reel/C_HYmILyqJ3/', 'https://www.instagram.com/sh.cookkook/reel/C_Fn9K0yzWY/', 'https://www.instagram.com/sh.cookkook/reel/C_E-HXXSJiZ/', 'https://www.instagram.com/sh.cookkook/reel/C_C2rgLyOvZ/', 'https://www.instagram.com/sh.cookkook/reel/C_CTGyVS4da/', 'https://www.instagram.com/sh.cookkook/reel/C_AMNBgyWrN/', 'https://www.instagram.com/sh.cookkook/reel/C-_n13XSbP3/', 'https://www.instagram.com/sh.cookkook/reel/C-92qPuSbcp/', 'https://www.instagram.com/sh.cookkook/reel/C-9DaPWyVl9/', 'https://www.instagram.com/sh.cookkook/reel/C-7MEVjSVn4/']\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 1. 웹드라이버 설정 및 인스타그램 로그인\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "# 인스타그램 로그인 페이지로 이동\n",
    "driver.get(\"https://www.instagram.com/accounts/login/\")\n",
    "time.sleep(5)  # 페이지 로드를 기다림\n",
    "\n",
    "# 로그인 정보 입력 (수동 로그인을 위해 시간을 더 줌)\n",
    "username = \"﻿snsdkf1234@naver.com\"\n",
    "password = \"wel1234\"\n",
    "\n",
    "driver.find_element(By.NAME, \"username\").send_keys(username)\n",
    "driver.find_element(By.NAME, \"password\").send_keys(password)\n",
    "driver.find_element(By.XPATH, '//*[@id=\"loginForm\"]/div/div[3]/button').click()\n",
    "\n",
    "\n",
    "# 로그인 후 대기 시간을 늘림\n",
    "time.sleep(10)\n",
    "\n",
    "# 2. 특정 계정으로 이동\n",
    "account_name = \"sh.cookkook\"\n",
    "driver.get(f\"https://www.instagram.com/{account_name}/\")\n",
    "time.sleep(5)\n",
    "\n",
    "# 스크롤을 내려 모든 게시물을 로드\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "time.sleep(5)\n",
    "\n",
    "# 3. 최근 7일간의 게시물 탐색 및 데이터 추출\n",
    "posts_data = []\n",
    "now = datetime.now()\n",
    "\n",
    "# XPath로 게시물 URL 추출\n",
    "post_elements = driver.find_elements(By.XPATH, '//article//a')\n",
    "\n",
    "# 게시물 URL 리스트 생성\n",
    "post_urls = [element.get_attribute('href') for element in post_elements]\n",
    "\n",
    "# 결과 출력\n",
    "print(post_urls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6c7cfa-2dbe-48fb-b0dd-518cff0eaed8",
   "metadata": {},
   "source": [
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee81e2a-6293-48a8-94d3-50a5def5fbc5",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38755a2e-18e1-42c7-86ed-78e3f317fe6f",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c13a6cb-d51e-467d-9986-877f29df054f",
   "metadata": {},
   "source": [
    "## 2. URL 기반 데이터 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1075e2b-a799-4aff-839a-55e9dbf236d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     account_name likes                                           hashtags  \\\n",
      "0    @sh.cookkook   N/A     #쿠히치, #압구정맛집, #강남맛집, #강남술집, #이자카야, #맛집추천, #규카츠   \n",
      "1    @sh.cookkook   N/A  #입분식가정집, #송파맛집, #송리단길, #송리단길맛집, #잠실맛집, #즉석떡볶이,...   \n",
      "2    @sh.cookkook   N/A  #컵속애, #노량진, #노량집컵밥, #노량진맛집, #동작맛집, #맛집추천, #컵냉면...   \n",
      "3    @sh.cookkook   N/A             #아리계곡, #강남맛집, #강남술집, #한식주점, #맛집추천, #백숙   \n",
      "4    @sh.cookkook   N/A             #수영냉삼, #부천맛집, #냉삼, #냉삼맛집, #서초갈비, #맛집추천   \n",
      "5    @sh.cookkook   N/A  #화반, #방이맛집, #잠실맛집, #송파맛집, #방이동맛집, #방이동먹자골목, #맛집추천   \n",
      "6   @cafe_dasique   N/A  #데이지크, #카페데이지크, #인마이디저트박스, #성수동데이트, #데이트코스, #성...   \n",
      "7    @sh.cookkook   N/A          #고래와치보, #강남맛집, #선릉맛집, #선릉술집, #강남술집, #이자카야   \n",
      "8    @sh.cookkook   N/A  #샤브올데이, #호텔식샤브뷔페, #별내맛집, #샤브샤브, #별내신도시, #남양주맛집...   \n",
      "9    @sh.cookkook   N/A                 #한사발포차, #닭도리탕, #떡도리탕, #안주맛집, #맛집추천   \n",
      "10   @sh.cookkook   N/A  #그리노성수, #성수맛집, #뇨끼맛집, #뚝섬맛집, #성수동맛집, #성수핫플, #맛...   \n",
      "11   @sh.cookkook   N/A          #이복희해장, #강남맛집, #선릉맛집, #강남술집, #해장맛집, #맛집추천   \n",
      "\n",
      "                                            post_text            post_date  \\\n",
      "0   sh.cookkook\\n아침 8시까지 놀다가세요\\n\\n압구정에 놀러간다? 그럼 여기...  2024-08-27 02:12:11   \n",
      "1   sh.cookkook\\n줄서는식당에도 나온 즉떡?\\n\\n어릴 적부터 주구장창 먹고자...  2024-08-26 08:33:29   \n",
      "2   sh.cookkook\\n올여름 난리난 가성비 간식💓\\n\\n와ㅜ 식당가면 기본 8천원...  2024-08-26 01:53:19   \n",
      "3   sh.cookkook\\n의외로 모른다는 강남에서 피서가는 법\\n\\n다들 여름이라 계...  2024-08-25 09:28:56   \n",
      "4   sh.cookkook\\n논란의 싸이냉삼, 부천 상륙?\\n\\n한 때 1인분(100g)...  2024-08-25 03:23:20   \n",
      "5   sh.cookkook\\n일단저장)40cm 롱갈매기살을 아시나요?\\n\\n잠실가서 고깃...  2024-08-24 07:40:16   \n",
      "6   sh.cookkook\\n화장대 디저트의 등장(?)\\n\\n코덕들은 다 아는 뷰티브랜드...  2024-08-24 07:35:34   \n",
      "7   sh.cookkook\\n일본행비행기 당장 취소해야하는 이유\\n\\n일본에서 유명한 테...  2024-08-23 06:54:23   \n",
      "8   sh.cookkook\\n60여가지 호텔식 샤브뷔페 2만원대?\\n\\n진심 최근 갔던 ...  2024-08-23 01:32:41   \n",
      "9   sh.cookkook\\n오픈과 동시에 만석이 되는 곳\\n\\n제가 평소에도 진짜 좋아...  2024-08-22 09:03:41   \n",
      "10  sh.cookkook\\n검은큐브 먹자는 여자친구 급증\\n\\n성수에 데이트하러 간다?...  2024-08-22 01:35:47   \n",
      "11  sh.cookkook\\n옛날 할머니 방식 그대로인 곳\\n\\n와.. 여기 메뉴들 진짜...  2024-08-21 08:13:24   \n",
      "\n",
      "             crawl_time                                           post_url  \n",
      "0   2024-08-27 13:44:50  https://www.instagram.com/sh.cookkook/reel/C_J...  \n",
      "1   2024-08-27 13:45:01  https://www.instagram.com/sh.cookkook/reel/C_I...  \n",
      "2   2024-08-27 13:45:12  https://www.instagram.com/sh.cookkook/reel/C_H...  \n",
      "3   2024-08-27 13:45:24  https://www.instagram.com/sh.cookkook/reel/C_F...  \n",
      "4   2024-08-27 13:45:35  https://www.instagram.com/sh.cookkook/reel/C_E...  \n",
      "5   2024-08-27 13:45:46  https://www.instagram.com/sh.cookkook/reel/C_C...  \n",
      "6   2024-08-27 13:45:57  https://www.instagram.com/sh.cookkook/reel/C_C...  \n",
      "7   2024-08-27 13:46:08  https://www.instagram.com/sh.cookkook/reel/C_A...  \n",
      "8   2024-08-27 13:46:20  https://www.instagram.com/sh.cookkook/reel/C-_...  \n",
      "9   2024-08-27 13:46:31  https://www.instagram.com/sh.cookkook/reel/C-9...  \n",
      "10  2024-08-27 13:46:42  https://www.instagram.com/sh.cookkook/reel/C-9...  \n",
      "11  2024-08-27 13:46:53  https://www.instagram.com/sh.cookkook/reel/C-7...  \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# 웹드라이버 설정\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "# 여러 개의 인스타그램 릴스 URL 리스트\n",
    "urls = ['https://www.instagram.com/sh.cookkook/reel/C_J_jvLSOzd/',\n",
    "         'https://www.instagram.com/sh.cookkook/reel/C_IGZmRyUU9/', \n",
    "         'https://www.instagram.com/sh.cookkook/reel/C_HYmILyqJ3/', \n",
    "         'https://www.instagram.com/sh.cookkook/reel/C_Fn9K0yzWY/',\n",
    "         'https://www.instagram.com/sh.cookkook/reel/C_E-HXXSJiZ/',\n",
    "         'https://www.instagram.com/sh.cookkook/reel/C_C2rgLyOvZ/', \n",
    "         'https://www.instagram.com/sh.cookkook/reel/C_CTGyVS4da/',\n",
    "         'https://www.instagram.com/sh.cookkook/reel/C_AMNBgyWrN/', \n",
    "         'https://www.instagram.com/sh.cookkook/reel/C-_n13XSbP3/',\n",
    "         'https://www.instagram.com/sh.cookkook/reel/C-92qPuSbcp/',\n",
    "         'https://www.instagram.com/sh.cookkook/reel/C-9DaPWyVl9/',\n",
    "         'https://www.instagram.com/sh.cookkook/reel/C-7MEVjSVn4/'\n",
    "        # 추가 URL\n",
    "        # 다른 URL도 여기에 추가 가능\n",
    "]\n",
    "\n",
    "data_list = []\n",
    "\n",
    "# 각 URL에서 데이터 추출\n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(10)  # 페이지 로드 대기\n",
    "\n",
    "    # 계정명 추출\n",
    "    try:\n",
    "        account_name = driver.find_element(By.XPATH, '//a[contains(@class, \"notranslate\")]').text\n",
    "    except:\n",
    "        account_name = \"N/A\"\n",
    "\n",
    "    # 좋아요 수 추출\n",
    "    try:\n",
    "        likes_element = driver.find_element(By.XPATH, '//div[contains(text(), \"likes\")]')\n",
    "        likes = likes_element.text.split(' ')[0]  # 'likes' 텍스트 앞의 숫자만 추출\n",
    "    except:\n",
    "        likes = \"N/A\"\n",
    "\n",
    "    # 해시태그 추출\n",
    "    try:\n",
    "        hashtags = [tag.text for tag in driver.find_elements(By.XPATH, '//a[contains(@href, \"/explore/tags/\")]')]\n",
    "        hashtags = hashtags[:10]  # 상위 10개 해시태그만 가져오기\n",
    "    except:\n",
    "        hashtags = []\n",
    "\n",
    "    # 본문 텍스트 추출\n",
    "    try:\n",
    "        post_text = driver.find_element(By.XPATH, '//div[@class=\"_a9zr\"]').text\n",
    "    except:\n",
    "        post_text = \"\"\n",
    "\n",
    "    # 게시 날짜 추출\n",
    "    try:\n",
    "        post_date_element = driver.find_element(By.XPATH, '//time')\n",
    "        post_date = post_date_element.get_attribute('datetime')\n",
    "        post_date = datetime.strptime(post_date, \"%Y-%m-%dT%H:%M:%S.%fZ\").strftime(\"%Y-%m-%d %H:%M:%S\")  # ISO 형식을 datetime으로 변환\n",
    "    except:\n",
    "        post_date = \"N/A\"\n",
    "\n",
    "    # 현재 크롤링 시간\n",
    "    crawl_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # 데이터 저장\n",
    "    data = {\n",
    "        'account_name': account_name,\n",
    "        'likes': likes,\n",
    "        'hashtags': ', '.join(hashtags),\n",
    "        'post_text': post_text,\n",
    "        'post_date': post_date,\n",
    "        'crawl_time': crawl_time,\n",
    "        'post_url': url\n",
    "    }\n",
    "\n",
    "    data_list.append(data)\n",
    "\n",
    "# 데이터프레임으로 변환\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# 결과 출력\n",
    "print(df)\n",
    "\n",
    "# CSV로 저장\n",
    "df.to_csv('instagram_post_data.csv', index=False)\n",
    "\n",
    "# 드라이버 종료\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb970600-ddda-44cd-9f53-2a3f672fe781",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252ebd02-4f2e-406c-b61b-cf84e0921dda",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6efed2-101b-4563-90d0-91f7875e6b3e",
   "metadata": {},
   "source": [
    "### [이슈]\n",
    "1. 개발시 크롤링을 너무 자주하면 url이 막히는 것 같음\n",
    "   > 비즈니스 계정이라 5번에 1번씩 막히는 이슈는 사라졌지만, 2-3시간이 한계인듯\n",
    "2. 좋아요 수는 추출이 안됨\n",
    "   > 좋아요 수가 꼭 필요할까? (더 찾아봐야함)\n",
    "\n",
    "### 검토 필요\n",
    "1. 회사의 IP로 영리목적의 데이터 수집에 대한 부분 * w/법무, 컴플라이언스\n",
    "2. (1번 확인 후) 외부 크롤링 자체 법적 및 보안 검토 * w/법무, 정보보호(둘 다)\n",
    "3. 사내망에서 크롤링이 가능할지 * w/정보보호\n",
    "   > 인스타그램 보안 사이트 막힘\n",
    "   > 크롤링 웹 페이지를 폐쇄망 서버에서 뿌리고있는데, 인스타그램 URL은 볼 수가없다.\n",
    "   > 활용 여부는 정보보호 협의 필요\n",
    "   \n",
    "==================\n",
    "1. ipynb을 python script로 변경해야 스케줄러 등록이 가능함\n",
    "2. 인스타 계정 ID/PW 코드 노출\n",
    "   > 해당 부분 코드 수정 필요\n",
    "3. for문을 통해 계정 4개를 한번하는 크롤링 -> 파일 떨구는 작업 필요\n",
    "   계정 목록 accounts = ['seoul__nadri', 'sh.cookkook', 'teddy_zip_', 'hye_foodie_']\n",
    "4. 8/29목 오전까지_ 웹화면 예쁘게 다듬기(서비스 배포용)\n",
    "5. DF 컬럼명 한글로 변경\n",
    "6. 파일 1개에 날짜 계속 쌓기\n",
    "7. 인스타 Like 가리기 \n",
    "8. 웹 - 회계숫자 날짜로 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b8c8f8-8e20-431b-a27e-bc02f224412c",
   "metadata": {},
   "source": [
    "240827_ \n",
    "1. (요청) 인스타 계정 수를 늘리고 게시물 갯수를 줄인다.\n",
    "   > 계정 30개, 게시물 3개씩.. 90개 \n",
    "   > (현재) 인스타 계정 4개, 게시글 12개 크롤링 = 48개\n",
    "2. 인스타 크롤링하는 과정을 영상(대시보드) 형태로 보여주는게 어떤지?\n",
    "   > 가시적으로 너무 좋음. 매일 아침 30분정도 보는것도 나쁘지 않을듯...\n",
    "   > 화면 녹화해서 FD 전달 후 영업사원 의견취합 \n",
    "3. 해주실 부분\n",
    "   > 11.71.35.34:30100 port 방화벽 해제 신청\n",
    "   > FD 영업사원 리뷰(해당 페이지 + 영상)\n",
    "   > 인스타 계정 추가(약 30개) - 팔로잉 해주신 뒤 말씀해주세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee2e3a3-d093-44fd-aa09-cbe30f3d50bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3cb05c75-f5da-4366-9431-ed34d5ac19ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'Results'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 112\u001b[0m\n\u001b[0;32m    109\u001b[0m df\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m#엑셀로 저장\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m df\u001b[38;5;241m.\u001b[39mto_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResults/Instagram_test.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    113\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32mD:\\apps\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\apps\\Lib\\site-packages\\pandas\\core\\generic.py:2414\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   2401\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2403\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2404\u001b[0m     df,\n\u001b[0;32m   2405\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2412\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2413\u001b[0m )\n\u001b[1;32m-> 2414\u001b[0m formatter\u001b[38;5;241m.\u001b[39mwrite(\n\u001b[0;32m   2415\u001b[0m     excel_writer,\n\u001b[0;32m   2416\u001b[0m     sheet_name\u001b[38;5;241m=\u001b[39msheet_name,\n\u001b[0;32m   2417\u001b[0m     startrow\u001b[38;5;241m=\u001b[39mstartrow,\n\u001b[0;32m   2418\u001b[0m     startcol\u001b[38;5;241m=\u001b[39mstartcol,\n\u001b[0;32m   2419\u001b[0m     freeze_panes\u001b[38;5;241m=\u001b[39mfreeze_panes,\n\u001b[0;32m   2420\u001b[0m     engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m   2421\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   2422\u001b[0m     engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m   2423\u001b[0m )\n",
      "File \u001b[1;32mD:\\apps\\Lib\\site-packages\\pandas\\io\\formats\\excel.py:943\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    941\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    942\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 943\u001b[0m     writer \u001b[38;5;241m=\u001b[39m ExcelWriter(\n\u001b[0;32m    944\u001b[0m         writer,\n\u001b[0;32m    945\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    946\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    947\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m    948\u001b[0m     )\n\u001b[0;32m    949\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\apps\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:61\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Workbook\n\u001b[0;32m     59\u001b[0m engine_kwargs \u001b[38;5;241m=\u001b[39m combine_kwargs(engine_kwargs, kwargs)\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     62\u001b[0m     path,\n\u001b[0;32m     63\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m     64\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m     65\u001b[0m     if_sheet_exists\u001b[38;5;241m=\u001b[39mif_sheet_exists,\n\u001b[0;32m     66\u001b[0m     engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m     67\u001b[0m )\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# ExcelWriter replaced \"a\" by \"r+\" to allow us to first read the excel file from\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# the file and later write to it\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode:  \u001b[38;5;66;03m# Load from existing workbook\u001b[39;00m\n",
      "File \u001b[1;32mD:\\apps\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1246\u001b[0m, in \u001b[0;36mExcelWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m IOHandles(\n\u001b[0;32m   1243\u001b[0m     cast(IO[\u001b[38;5;28mbytes\u001b[39m], path), compression\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m   1244\u001b[0m )\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, ExcelWriter):\n\u001b[1;32m-> 1246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1247\u001b[0m         path, mode, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1248\u001b[0m     )\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cur_sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m date_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\apps\\Lib\\site-packages\\pandas\\io\\common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 749\u001b[0m     check_parent_directory(\u001b[38;5;28mstr\u001b[39m(handle))\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32mD:\\apps\\Lib\\site-packages\\pandas\\io\\common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'Results'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# 1. 웹드라이버 설정 및 인스타그램 로그인\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "# 인스타그램 로그인 페이지로 이동\n",
    "driver.get(\"https://www.instagram.com/accounts/login/\")\n",
    "time.sleep(3)  # 페이지 로드를 기다림\n",
    "\n",
    "# 로그인 정보 입력 (수동 로그인을 위해 시간을 더 줌)\n",
    "username = \"﻿snsdkf1234@naver.com\"\n",
    "password = \"wel1234\"\n",
    "\n",
    "driver.find_element(By.NAME, \"username\").send_keys(username)\n",
    "driver.find_element(By.NAME, \"password\").send_keys(password)\n",
    "driver.find_element(By.XPATH, '//*[@id=\"loginForm\"]/div/div[3]/button').click()\n",
    "time.sleep(3)  # 로그인 후 대기\n",
    "\n",
    "# 2. 특정 계정으로 이동\n",
    "# account_name = \"seoul__nadri\"  # 크롤링할 계정의 사용자 이름\n",
    "# driver.get(f\"https://www.instagram.com/{account_name}/\")\n",
    "# time.sleep(3)\n",
    "\n",
    "# 3. 최근 7일간의 게시물 탐색 및 데이터 추출\n",
    "posts_data = []\n",
    "now = datetime.now()\n",
    "\n",
    "\n",
    "# 데이터 저장을 위한 리스트 초기화\n",
    "App = \"Instagram\"\n",
    "data = []\n",
    "\n",
    "# 계정 목록 (예: 사용자 계정)\n",
    "accounts = ['seoul__nadri', 'sh.cookkook', 'teddy_zip_', 'hye_foodie_']\n",
    "\n",
    "for account in accounts:\n",
    "    # 특정 계정으로 이동\n",
    "    driver.get(f\"https://www.instagram.com/{account}/\")\n",
    "    time.sleep(7)\n",
    "    post_elements = driver.find_elements(By.XPATH, '//article//a')\n",
    "    post_urls = [element.get_attribute('href') for element in post_elements]\n",
    "    \n",
    "    for url in post_urls[0:1]: #5개만 테스트. 최대 계정당 12개만 가능\n",
    "        print(url)\n",
    "        driver.get(url)\n",
    "        time.sleep(10)  # 페이지 로드 대기\n",
    "\n",
    "        # 계정명 추출\n",
    "        try:\n",
    "            account_name = driver.find_element(By.XPATH, '//a[contains(@class, \"notranslate\")]').text\n",
    "        except:\n",
    "            account_name = \"N/A\"\n",
    "\n",
    "        # 좋아요 수 추출\n",
    "        try:\n",
    "            likes_element = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, '//div[contains(text(), \"likes\")]'))\n",
    "            )\n",
    "            likes = likes_element.text.split(' ')[0]  # 'likes' 텍스트 앞의 숫자만 추출\n",
    "        except:\n",
    "            likes = \"N/A\"\n",
    "        \n",
    "        # 해시태그 추출\n",
    "        try:\n",
    "            hashtags = [tag.text for tag in driver.find_elements(By.XPATH, '//a[contains(@href, \"/explore/tags/\")]')]\n",
    "            hashtags = hashtags[:10]  # 상위 10개 해시태그만 가져오기\n",
    "        except:\n",
    "            hashtags = []\n",
    "        \n",
    "        # 본문 텍스트 추출\n",
    "        try:\n",
    "            post_text = driver.find_element(By.XPATH, '//div[@class=\"_a9zr\"]').text\n",
    "        except:\n",
    "            post_text = \"\"\n",
    "        \n",
    "        # 게시 날짜 추출\n",
    "        try:\n",
    "            post_date_element = driver.find_element(By.XPATH, '//time')\n",
    "            post_date = post_date_element.get_attribute('datetime')\n",
    "            post_date = datetime.strptime(post_date, \"%Y-%m-%dT%H:%M:%S.%fZ\").strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        except:\n",
    "            post_date = \"N/A\"\n",
    "        \n",
    "        # 현재 크롤링 시간\n",
    "        crawl_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        line_data = []\n",
    "        line_data.append(App)\n",
    "        line_data.append(account_name)\n",
    "        line_data.append(likes)\n",
    "        line_data.append(', '.join(hashtags))\n",
    "        line_data.append(post_text)\n",
    "        line_data.append(post_date)\n",
    "        line_data.append(crawl_time)\n",
    "        line_data.append(url)\n",
    "        data.append(line_data)\n",
    "\n",
    "# 4. 데이터프레임 생성 및 CSV 저장\n",
    "df = pd.DataFrame(data, columns= ['App','Account_name', 'Likes', 'Hashtags', 'Post_text', 'Post_date', 'Crawl_time', 'Post_url'])\n",
    "df.index = df.index+1\n",
    "df\n",
    "\n",
    "#엑셀로 저장\n",
    "df.to_excel('Results/Instagram_test.xlsx')\n",
    "time.sleep(3)\n",
    "# driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2756afc-5d76-44ff-8441-2b4661346c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33ebee8-8098-4564-9329-806e7b10855e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
